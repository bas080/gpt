#!/usr/bin/env bash

set -euo pipefail

readonly GPT_API="https://openrouter.ai/api/v1/chat/completions"
readonly GPT_MODEL="${GPT_MODEL:-openai/gpt-4o}"
readonly GPT_KEY="${GPT_KEY:?-Please define gpt key}"
readonly GPT_CONTEXT="${GPT_CONTEXT:-/tmp/gpt.$WINDOWID}"
readonly GPT_PROMPT="${GPT_PROMPT:-/tmp/gpt.$WINDOWID.prompt}"
readonly GPT_TEMPERATURE="${GPT_TEMPERATURE:-0.7}"
readonly GPT_MAX_LINES="${GPT_MAX_LINES:-40}"
readonly GPT_MAX_TOKENS="${GPT_MAX_TOKENS:- 400}"

if [ ! -f "$GPT_PROMPT" ]; then
  echo "" > "$GPT_PROMPT"
fi

{
  echo "
  PROMPT:  $GPT_PROMPT
  CONTEXT: $GPT_CONTEXT
  MODEL:   $GPT_MODEL
  "
} 1>&2

mkdir -p ~/.config/gpt/context

function handle_exit {
  local status=$?
  if [ $status -ne 0 ]; then
    echo "Script failed with status code $status on command: $BASH_COMMAND" >&2
  fi
}
trap handle_exit EXIT

if [ -z "$*" ] && [ -t 0 ]; then
  touch "$GPT_CONTEXT"
  "$EDITOR" "$GPT_CONTEXT"
fi

if [ ! -t 0 ]; then
  jq -Rsc '{role:"user", content:.}' >> "$GPT_CONTEXT"
fi

if [ -n "$*" ]; then
  jq -nc --arg content "$*" '{role:"user", content:$content}' >> "$GPT_CONTEXT"
fi

function pretty_print {
  cat -
}

# Build JSON for request: use PROMPT and last N lines from GPT_CONTEXT
jq --null-input \
  --arg MODEL "$GPT_MODEL" \
  --arg TOKENS "$GPT_MAX_TOKENS" \
  --argjson HISTORY "$(tail -n "$GPT_MAX_LINES" "$GPT_CONTEXT" | jq -s '.')" \
  --arg SYSTEM "$(cat "$GPT_PROMPT")" \
'{
  model: $MODEL,
  max_tokens: $TOKENS,
  messages: ([{role:"system", content:$SYSTEM}] + $HISTORY),
  temperature: '"$GPT_TEMPERATURE"'
}' | curl --fail-early -s \
  -H "Authorization: Bearer $GPT_KEY" \
  -H "Content-Type: application/json" \
  -X POST "$GPT_API" \
  --data-binary @- |
  jq -e -r '.choices[0].message.content' |
  tee >(jq -Rcs '{role:"assistant", content:.}' >> "$GPT_CONTEXT")
